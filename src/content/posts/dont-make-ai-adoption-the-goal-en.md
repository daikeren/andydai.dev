---
title: Don't Make "AI Adoption" the Goal Itself
published: 2026-02-01
description: Many companies obsess over "which AI tool is best," but the real question is—where is efficiency currently blocked? If basic digitization and process standardization aren't in place, switching to a stronger model just means spending more money.
tags: [ai-adoption, digital-transformation, startup]
lang: en
abbrlink: dont-make-ai-adoption-the-goal
toc: true
faqs:
  - question: What question should you ask before adopting AI?
    answer: First ask "what specifically am I trying to achieve." If the answer is higher efficiency, the next question is "where is efficiency currently blocked."
  - question: For general industries, is a general model sufficient, or do you need a fine-tuned specialized model?
    answer: In most cases, general models (like Opus, GPT) are sufficient. What's needed isn't a more powerful model, but sufficient context—internal data, documents, and datasets.
  - question: What's the most common mistake in AI adoption?
    answer: Making "AI adoption" itself the goal rather than a means. As a result, the real problems that need solving (personnel training, process digitization) get ignored.
---

> **TL;DR**: Obsessing over "which AI tool is best" is asking the wrong question. The real question is: where is efficiency currently blocked? If personnel training and process digitization aren't in place, switching to a stronger model just means spending more money. Start using it first—needs will naturally emerge.

## When Comparing AI Tools, You're Already Asking the Wrong Question

My brother is the R&D manager at a food company. Recently he told me they've been surveying AI tools to assist with research, but after studying for a while, they still don't know which one to choose.

I asked what they're comparing. He said they're comparing whether various models have been fine-tuned specifically for food research.

Hearing this, my first reaction was: general models (like Opus, GPT 5.2) should be plenty sufficient. What's needed isn't a more powerful model, but sufficient context—papers, their food ingredient sources, experimental data, customer feedback on products, that kind of thing.

I told him this directly. His response: "But isn't how good the tool is still important?"

Honestly, obsessing over which model is better is already asking the wrong question.

I told him: just pick one and start using it. After using it for a while, you'll naturally find the problem isn't the AI tool at all—it's these two things: First, how do you train existing personnel to use AI more effectively? Second, is all the support needed for research—paper searches, research data, lab equipment records, research documents, even the process itself—sufficiently digitized and standardized? Can AI access it?

If these two questions don't have good answers, then even using GPT-6 (hypothetically) with OpenAI's internal research-specialized Agent would just mean spending more money for them.

I asked if these things were digitized. He thought for a moment and said: "Of course not."

---

## This Isn't the First Time I've Seen This

This reminded me of consulting experience from a few years ago.

My client was a traditional publishing company worrying about how to make the whole company more digital. They did one thing: converted all content published over the past twenty to thirty years into PDFs. After converting everything, they found this "digitization" was meaningless—it couldn't be searched or reused.

Then nothing came of it. That's the cost of making means into ends.

---

## Making Means Into Ends

The problem behind both stories is the same: only thinking about wanting to "digitize" or "adopt AI," without thinking further about what the purpose behind it is. Making adoption itself the goal, rather than a means.

I asked my brother: "What effect are you really trying to achieve by adopting AI?" He thought for a moment and said: "We hope everyone's research and development efficiency can improve."

Then the question becomes: where is efficiency currently blocked? Is it because there's no good AI tool, or are there more fundamental things not yet in place?

---

## My Advice: Just Start Using It

My advice is simple: start with basic Gemini, ChatGPT, or Claude. After everyone's proficient at using AI, needs like "can AI search our internal database" will naturally emerge. Then gradually integrate these processes step by step.

Our own team's [AI coding agent adoption](/en/posts/ai-native-engineering-team/) was the same—start using it, needs will naturally emerge.

---

## What to Ask Yourself Before Adopting AI

Before adopting any technology or process, first ask yourself: what specifically am I trying to achieve? If the answer is "higher efficiency," the next question is: where is efficiency currently blocked?

When "AI adoption" becomes the goal itself, the real problems that need solving get ignored.
